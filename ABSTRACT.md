The creators of the **38-Clouds** dataset present an innovative deep learning algorithm designed to accurately identify clouds in satellite images, especially when working with a limited set of available spectral bands. This algorithm employs a fully convolutional network (FCN) known as **Cloud-Net**, which is trained using various patches extracted from Landsat 8 satellite images. Cloud-Net is specifically crafted to efficiently capture global and local cloud features within an image through its convolutional components. An important feature of this approach is its end-to-end nature, eliminating the requirement for intricate preprocessing procedures.

The accurate measurement and identification of cloud coverage bear immense importance in analysing satellite imagery, as clouds can obscure land-based objects and pose challenges for various remote sensing applications, including change detection, geophysical parameter retrieval, and object tracking. Moreover, transmitting images with substantial cloud cover from satellites to ground stations proves unnecessary and inefficient. Cloud coverage data can also offer valuable insights into climate parameters and natural disasters, such as hurricanes and volcanic eruptions. Consequently, identifying cloud regions within images emerges as a pivotal preprocessing step across multiple applications.

To train Cloud-Net, the authors harnessed Landsat 8 spectral images, which encompass eleven spectral bands. Four of these bands (from band 2 to band 5) were selected for utilization in their research, as they are among the more commonly accessible bands provided by numerous remote sensing satellites like Sentinel-2, HJ-1, GF-2, among others. Given the substantial spatial dimensions of Landsat 8 images, the authors extracted multiple non-overlapping patches, each measuring 384 × 384 pixels, from these images. Before inputting them into Cloud-Net, these patches underwent downsizing to 192 × 192 pixels and normalization by dividing by 65535. Consequently, the input size of the network stands at 192 × 192 × 4, while the output cloud mask dimensions are 192 × 192 × 1.

Regarding the dataset utilized for training and testing, the authors drew from the dataset introduced in a prior study with some modifications. This dataset encompasses 18 Landsat 8 images for training and 20 images for testing. During their assessment, the authors identified five images (four from the _training_ set and one from the _test_ set) with inaccurate and uncertain ground truths (GTs). These problematic images were subsequently replaced with five new images. Additionally, the GTs for all images in the training set underwent manual annotation, departing from the automatically generated GTs employed in the previous dataset. This adjustment contributes to the algorithm's performance, as it enables the network to learn cloud features from accurate images and GTs instead of inconsistent data. After cropping the images into 384 × 384 multiband patches, the dataset yields 8400 patches for training and 9201 patches for testing, all of which Cloud-Net is trained on.

In the test phase, to generate the cloud mask for an unseen test image, the image is initially divided into multiple non-overlapping patches measuring 384 × 384 pixels. Subsequently, each patch undergoes normalization (without downsizing to 192 × 192) before being input into Cloud-Net.
