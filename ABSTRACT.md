In the realm of remote sensing applications, the precise detection of clouds in satellite images plays a pivotal role. Addressing this challenge becomes more intricate when dealing with a limited number of available spectral bands. To tackle this issue, the authors of the **38-Clous** dataset introduce a deep learning-based algorithm in their research. This algorithm features a fully convolutional network (FCN) named **Cloud-Net**, trained using multiple patches extracted from Landsat 8 images. Cloud-Net is engineered to effectively capture both global and local cloud characteristics within an image through its convolutional blocks. Notably, this method represents an end-to-end solution, eliminating the need for complex preprocessing steps.

The accurate measurement and identification of cloud coverage bear immense importance in the analysis of satellite imagery, as clouds can obscure land-based objects and pose challenges for various remote sensing applications, including change detection, geophysical parameter retrieval, and object tracking. Moreover, transmitting images with substantial cloud cover from satellites to ground stations proves unnecessary and inefficient. Cloud coverage data can also offer valuable insights into climate parameters and natural disasters, such as hurricanes and volcanic eruptions. Consequently, the identification of cloud regions within images emerges as a pivotal preprocessing step across multiple applications.

To train Cloud-Net, the authors harnessed Landsat 8 spectral images, which encompass eleven spectral bands. Four of these bands (from band 2 to band 5) were selected for utilization in their research, as they are among the more commonly accessible bands provided by numerous remote sensing satellites like Sentinel-2, HJ-1, GF-2, among others. Given the substantial spatial dimensions of Landsat 8 images, the authors extracted multiple non-overlapping patches, each measuring 384 × 384 pixels, from these images. Before inputting them into Cloud-Net, these patches underwent downsizing to 192 × 192 pixels and normalization by dividing by 65535. Consequently, the input size of the network stands at 192 × 192 × 4, while the output cloud mask dimensions are 192 × 192 × 1.

Regarding the dataset utilized for training and testing, the authors drew from the dataset introduced in a prior study with some modifications. This dataset encompasses 18 Landsat 8 images for training and 20 images for testing. During their assessment, the authors identified five images (four from the _training_ set and one from the _test_ set) with inaccurate and uncertain ground truths (GTs). These problematic images were subsequently replaced with five new images. Additionally, the GTs for all images in the training set underwent manual annotation, departing from the automatically generated GTs employed in the previous dataset. This adjustment contributes to the algorithm's performance, as it enables the network to learn cloud features from accurate images and GTs instead of inconsistent data. After cropping the images into 384 × 384 patches, the dataset yields 8400 patches for training and 9201 patches for testing, all of which Cloud-Net is trained on.

In the test phase, to generate the cloud mask for an unseen test image, the image is initially divided into multiple non-overlapping patches measuring 384 × 384 pixels. Subsequently, each patch undergoes normalization (without downsizing to 192 × 192) before being input into Cloud-Net.
